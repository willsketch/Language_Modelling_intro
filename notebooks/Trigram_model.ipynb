{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e359238",
   "metadata": {},
   "source": [
    "# Opening and exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0cda99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13df5b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/william/language_modelling_andrej/intro_pytorch/Language_Modelling_intro/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a68e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../raw_data/names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd38dec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c5c48",
   "metadata": {},
   "source": [
    "# Counting model\n",
    "counting model would require a very long tensor due to the many possible combinations (27*26)\n",
    "so for that reason i will use the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b49b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts= {}\n",
    "for word in words:\n",
    "    word = list('.' + word + '.')\n",
    "    for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        counts[trigram] = counts.get(trigram, 0) + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bea2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(counts.items());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319cbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(counts.items(),key= lambda x: x[1], reverse=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "994213a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating mappings of bigram to int and int to bigram\n",
    "unique = sorted(list(set(''.join(words))) + ['.'])\n",
    "btoi = {} # bigram to int \n",
    "stoi = {s:i+1 for i, s in enumerate(unique[1:])}\n",
    "stoi['.'] = 0\n",
    "count= 0\n",
    "for s in unique:\n",
    "    for c in unique:\n",
    "        bigram = s + c\n",
    "        btoi[bigram]= count\n",
    "        count+=1\n",
    "\n",
    "btoi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319b0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse of btoi and stoi\n",
    "itos = {v:k for k, v in stoi.items()}\n",
    "itob = {v:k for k, v in btoi.items()}\n",
    "itob;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38580361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counts matrix\n",
    "N = torch.zeros((729, 27), dtype=torch.int32)\n",
    "for word in words:\n",
    "    word = list('.' + word + '.')\n",
    "    for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "        bigram = ch1 + ch2\n",
    "        ix1 = btoi[bigram]\n",
    "        string = ch3\n",
    "        ix2 = stoi[ch3]\n",
    "        N[ix1, ix2] +=1\n",
    "#         print(f'{bigram=},   {ix1=},    {ch3=},   {ix2=}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac7300a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed6ed9",
   "metadata": {},
   "source": [
    "# Neural network model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "916d2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196113\n"
     ]
    }
   ],
   "source": [
    "# creating dataset\n",
    "xs = []\n",
    "ys = []\n",
    "for word in words:\n",
    "    word = list('.' + word + '.')\n",
    "    for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "        bigram = ch1 + ch2\n",
    "        ix1 = btoi[bigram]\n",
    "        string = ch3\n",
    "        ix2 = stoi[ch3]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "#         print(f'{bigram=},   {ix1=},    {ch3=},   {ix2=}')\n",
    "xs = torch.tensor(xs)\n",
    "num = xs.nelement()\n",
    "print(num)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f851934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5, 148, 364,  ..., 727, 701, 726])\n",
      "tensor([13, 13,  1,  ..., 26, 24,  0])\n"
     ]
    }
   ],
   "source": [
    "print(xs)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db2d47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "g = torch.Generator().manual_seed(0)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d34ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=2.5018551349639893,   epoch=0\n",
      "loss.item()=2.501757860183716,   epoch=1\n",
      "loss.item()=2.5016608238220215,   epoch=2\n",
      "loss.item()=2.501563787460327,   epoch=3\n",
      "loss.item()=2.501466989517212,   epoch=4\n",
      "loss.item()=2.501370906829834,   epoch=5\n",
      "loss.item()=2.501274347305298,   epoch=6\n",
      "loss.item()=2.501178503036499,   epoch=7\n",
      "loss.item()=2.5010828971862793,   epoch=8\n",
      "loss.item()=2.5009870529174805,   epoch=9\n",
      "loss.item()=2.500891923904419,   epoch=10\n",
      "loss.item()=2.5007967948913574,   epoch=11\n",
      "loss.item()=2.500701427459717,   epoch=12\n",
      "loss.item()=2.5006070137023926,   epoch=13\n",
      "loss.item()=2.5005123615264893,   epoch=14\n",
      "loss.item()=2.500418186187744,   epoch=15\n",
      "loss.item()=2.500324249267578,   epoch=16\n",
      "loss.item()=2.500230312347412,   epoch=17\n",
      "loss.item()=2.500136613845825,   epoch=18\n",
      "loss.item()=2.5000433921813965,   epoch=19\n",
      "loss.item()=2.4999501705169678,   epoch=20\n",
      "loss.item()=2.499856948852539,   epoch=21\n",
      "loss.item()=2.4997642040252686,   epoch=22\n",
      "loss.item()=2.499671697616577,   epoch=23\n",
      "loss.item()=2.4995791912078857,   epoch=24\n",
      "loss.item()=2.4994869232177734,   epoch=25\n",
      "loss.item()=2.4993951320648193,   epoch=26\n",
      "loss.item()=2.4993033409118652,   epoch=27\n",
      "loss.item()=2.4992117881774902,   epoch=28\n",
      "loss.item()=2.4991204738616943,   epoch=29\n",
      "loss.item()=2.4990293979644775,   epoch=30\n",
      "loss.item()=2.4989383220672607,   epoch=31\n",
      "loss.item()=2.498847723007202,   epoch=32\n",
      "loss.item()=2.4987571239471436,   epoch=33\n",
      "loss.item()=2.498666763305664,   epoch=34\n",
      "loss.item()=2.4985766410827637,   epoch=35\n",
      "loss.item()=2.4984867572784424,   epoch=36\n",
      "loss.item()=2.4983971118927,   epoch=37\n",
      "loss.item()=2.498307704925537,   epoch=38\n",
      "loss.item()=2.498218536376953,   epoch=39\n",
      "loss.item()=2.498129367828369,   epoch=40\n",
      "loss.item()=2.4980406761169434,   epoch=41\n",
      "loss.item()=2.4979515075683594,   epoch=42\n",
      "loss.item()=2.497863292694092,   epoch=43\n",
      "loss.item()=2.497774839401245,   epoch=44\n",
      "loss.item()=2.4976866245269775,   epoch=45\n",
      "loss.item()=2.497598648071289,   epoch=46\n",
      "loss.item()=2.497511148452759,   epoch=47\n",
      "loss.item()=2.4974236488342285,   epoch=48\n",
      "loss.item()=2.4973363876342773,   epoch=49\n",
      "loss.item()=2.497249126434326,   epoch=50\n",
      "loss.item()=2.497162342071533,   epoch=51\n",
      "loss.item()=2.4970757961273193,   epoch=52\n",
      "loss.item()=2.4969892501831055,   epoch=53\n",
      "loss.item()=2.4969027042388916,   epoch=54\n",
      "loss.item()=2.496816635131836,   epoch=55\n",
      "loss.item()=2.4967308044433594,   epoch=56\n",
      "loss.item()=2.496644973754883,   epoch=57\n",
      "loss.item()=2.4965591430664062,   epoch=58\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes = 729).float()\n",
    "for epoch in range(100):\n",
    "    # forward pass\n",
    "    W.grad= None\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs= counts/counts.sum(dim=1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + (W**2).mean()\n",
    "    print(f'{loss.item()=},   {epoch=}')\n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    W.data+= -10*W.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c6ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zlkwstdhlfncelihheqtdraidkoqsfupfclynana\n",
      "bremiu\n",
      "zuuefzulkr\n",
      "pla\n",
      "zhchtcusrjt\n",
      "hacjfdmkflopjmelsx\n",
      "tabdrmbzqnjzjzugrfmcrailtifqby\n",
      "xfoaapalxiddumoevltbmjcsrayroqslivqius\n",
      "wqzg\n",
      "na\n",
      "qympgupfhvffejydetqueandrwwsogptlsjdwjdezffckeuzcdel\n",
      "jvibraveowteikqdqrlbdzipli\n",
      "larsw\n",
      "bidgopzzzzzpwana\n",
      "fxten\n",
      "re\n",
      "dbsslpxgqwdgjvotolfa\n",
      "rej\n",
      "laysmfmfmjzmfkrvbjppbzxngtdhlion\n",
      "vgzqngty\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(0)\n",
    "for i in range(20):\n",
    "    pred_word =['.']\n",
    "    ix=0   \n",
    "    while True:\n",
    "        previous_char = pred_word[-1]\n",
    "        xenc =  F.one_hot(torch.tensor([ix]), num_classes=729).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp() # equivalent to counts_tensor\n",
    "        prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "        ix = torch.multinomial(prob, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix ==0:\n",
    "            break \n",
    "        next_char = itos[ix]\n",
    "        bigram = previous_char + next_char\n",
    "        ix = btoi[bigram]\n",
    "        pred_word.append(next_char)\n",
    "    print(''.join(pred_word[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2db971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('y', 'y', 'ty', 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_char, next_char, bigram, ix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
